{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lambda_Function.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+pIRf7AKBX9sAPiJybve4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedeEzeq/ML2---Chatbot-en-Google-Cloud/blob/main/Lambda_Function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQ0g2Kfw4B-o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import unicodedata\n",
        "import spacy_stanza\n",
        "import requests\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "os.system(\"gsutil cp gs://chatbot_ml2/words.pkl words.pkl\")\n",
        "os.system(\"gsutil cp gs://chatbot_ml2/classes.pkl classes.pkl\")\n",
        "\n",
        "words_file = open(\"words.pkl\",'rb')\n",
        "words = pickle.load(words_file)\n",
        "words_file.close()\n",
        "\n",
        "classes_file = open(\"classes.pkl\",'rb')\n",
        "classes = pickle.load(classes_file)\n",
        "classes_file.close()\n",
        "\n",
        "nlp = spacy_stanza.load_pipeline(\"es\")\n",
        "\n",
        "def preprocess_clean_text(text):    \n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "  \n",
        "def text_to_tokens(text): \n",
        "    lemma_tokens = []\n",
        "    tokens = nlp(preprocess_clean_text(text.lower()))\n",
        "    for token in tokens:\n",
        "        lemma_tokens.append(token.lemma_)\n",
        "    return lemma_tokens\n",
        "\n",
        "def bag_of_words(text, vocab): \n",
        "    tokens = text_to_tokens(text)\n",
        "    bow = [0] * len(vocab)\n",
        "    for w in tokens: \n",
        "        for idx, word in enumerate(vocab):\n",
        "            if word == w: \n",
        "                bow[idx] = 1\n",
        "    return np.array(bow)\n",
        "\n",
        "\n",
        "def mensaje_alumno (external_request):\n",
        "  \n",
        "  headers = {}\n",
        "  external_request = external_request.json\n",
        "  data = external_request['data']\n",
        "  data2 = bag_of_words(data,words)\n",
        " \n",
        " \n",
        "  #columns = external_request['columns']\n",
        "  headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "        }\n",
        "\n",
        "  json_data = {\"columns\": [\"X\"],\"data\": data2}\n",
        "  response = requests.post('http://34.134.63.173:5000/invocations', headers=headers, json=json_data)\n",
        "\n",
        "  thresh = 0.2\n",
        "        y_pred = [[idx, res] for idx, res in enumerate(response) if res > thresh] \n",
        "        y_pred.sort(key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "        for r in y_pred:\n",
        "            return_list.append(labels[r[0]])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  return str(response.text)\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#MODEL PREDICT \n",
        "def pred_class(text, vocab, labels): \n",
        "    bow = bag_of_words(text, vocab)\n",
        "    words_recognized = sum(bow)\n",
        "\n",
        "    return_list = []\n",
        "    if words_recognized > 0:\n",
        "        result = model.predict(np.array([bow]))[0] #vector de largo = cantidad de clases, \n",
        "        thresh = 0.2\n",
        "        y_pred = [[idx, res] for idx, res in enumerate(result) if res > thresh] \n",
        "        y_pred.sort(key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "        for r in y_pred:\n",
        "            return_list.append(labels[r[0]])\n",
        "            #print(labels[r[0]], r[1])\n",
        "\n",
        "    return return_list\n",
        "\n",
        "def get_response(intents_list, intents_json):\n",
        "    tag = intents_list[0]\n",
        "    list_of_intents = intents_json[\"intents\"]\n",
        "    for i in list_of_intents: \n",
        "        if i[\"tag\"] == tag:\n",
        "            result = \"BOT: \" + random.choice(i[\"responses\"])\n",
        "            break\n",
        "    return result\n",
        "\n",
        "\n",
        "#INTERACCION CON ALUMNO\n",
        "while True:\n",
        "    message = input(\"\")\n",
        "    intents = pred_class(message, words, classes)\n",
        "    if len(intents) > 0:\n",
        "        result = get_response(intents, dataset)\n",
        "        print(result)\n",
        "    else:\n",
        "        print(\"Perd√≥n, no comprendo la pregunta.\")\n",
        "    "
      ]
    }
  ]
}